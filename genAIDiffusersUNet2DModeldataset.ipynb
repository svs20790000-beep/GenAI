
#pip install diffusers[training]==0.2.3
#pip install "ipywidgets>=7,<8"
import tensorflow as tf
from huggingface_hub import hf_hub_download
from skimage.util import random_noise
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

# Pytorch
import torch
import torchvision

# HuggingFace
import datasets
import diffusers
import accelerate


# Training and Visualization
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
import os
import PIL

from dataclasses import dataclass

@dataclass
class TrainingConfig:
    image_size=32 #Resize the digits to be a power of two
    train_batch_size = 32
    eval_batch_size = 32
    num_epochs = 5
    gradient_accumulation_steps = 1
    learning_rate = 1e-4
    lr_warmpup_steps = 500
    mixed_precision = 'fp16'
    seed = 0
    
config = TrainingConfig()

#model_path = hf_hub_download(repo_id="BueormLLC/AID", filename="model.h5")
#autoencoder = tf.keras.models.load_model(model_path, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})
#def add_noise(img, noise_type="gaussian"):
#    img_np = img.numpy()
#    if noise_type == "gaussian":
#        noisy_img = random_noise(img_np, mode='gaussian', var=0.1)
#    elif noise_type == "salt_pepper":
#        noisy_img = random_noise(img_np, mode='s&p', amount=0.1)
#    return np.clip(noisy_img, 0., 1.)
#def predict_denoised_image(autoencoder, image):
#    img_resized = tf.image.resize(image, (256, 256)) / 255.0
#    img_array = np.expand_dims(img_resized, axis=0)
#    noisy_image = add_noise(img_resized)
#    denoised_image = autoencoder.predict(np.expand_dims(noisy_image, axis=0))
#    fig, ax = plt.subplots(1, 2, figsize=(10, 5))
#    ax[0].imshow(noisy_image)
#    ax[0].set_title("Noisy Image")
#    ax[0].axis('off')
#    ax[1].imshow(denoised_image[0])
#    ax[1].set_title("Denoised Image")
#    ax[1].axis('off')
#    plt.show()


def transform(dataset):
    preprocess = torchvision.transforms.Compose(
        [
            torchvision.transforms.Resize(
                (config.image_size, config.image_size)),
            torchvision.transforms.ToTensor(),
            torchvision.transforms.Lambda(lambda x: 2*(x-0.5)),
        ]
    )
    images = [preprocess(image) for image in dataset["image"]]
    return {"images": images}


mnist_dataset = datasets.load_dataset('mnist', split='train')
mnist_dataset
mnist_dataset[0]["image"].resize((256, 256)).show()
print("Image Size:", mnist_dataset[0]["image"].size)
print("Digit is labelled:", mnist_dataset[0]['label'])

mnist_dataset.reset_format()
mnist_dataset.set_transform(transform)

train_dataloader = torch.utils.data.DataLoader(
    mnist_dataset,
    batch_size = config.train_batch_size,
    shuffle = True,
)

model = diffusers.UNet2DModel(
    sample_size=config.image_size,
    in_channels=1,
    out_channels=1,
    layers_per_block=2,
    block_out_channels=(128,128,256,512),
    down_block_types=(
        "DownBlock2D",
        "DownBlock2D",
        "AttnDownBlock2D",
        "DownBlock2D",
    ),
    up_block_types=(
        "UpBlock2D",
        "AttnUpBlock2D",
        "UpBlock2D",
        "UpBlock2D",
    ),
)

sample_image = mnist_dataset[0]["images"].unsqueeze(0)
print("Input shape:", sample_image.shape)

noise_scheduler = diffusers.DDPMScheduler(num_train_timesteps=200, tensor_format='pt')

print("Original Digit")
torchvision.transforms.ToPILImage()(sample_image.squeeze(1)).resize((256,256))

noise = torch.randn(sample_image.shape)
timesteps = torch.LongTensor([199])
noisy_image = noise_scheduler.add_noise(sample_image,noise,timesteps)

print("Fully Noised Digit")
torchvision.transforms.ToPILImage()(noisy_image.squeeze(1)).resize((256,256))

optimizer = torch.optim.AdamW(model.parameters(),lr=config.learning_rate)

# Cosine learning rate scheduler

lr_scheduler = diffusers.optimization.get_cosine_schedule_with_warmup(
    optimizer=optimizer,
    num_warmup_steps=config.lr_warmpup_steps,
    num_training_steps=(len(train_dataloader)*config.num_epochs),
)

def train_loop(
        config,
        model,
        noise_scheduler,
        optimizer,
        train_dataloader,
        lr_scheduler):

    accelerator = accelerate.Accelerator(
        mixed_precision=config.mixed_precision,
        gradient_accumulation_steps=config.gradient_accumulation_steps,
    )

    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
        model, optimizer, train_dataloader, lr_scheduler
    )

    for epoch in range(config.num_epochs):
        progress_bar = tqdm(total=len(train_dataloader),
                            disable=not accelerator.is_local_main_process)
        progress_bar.set_description(f"Epoch {epoch}")

        for step, batch in enumerate(train_dataloader):
            clean_images = batch['images']

            noise = torch.randn(clean_images.shape).to(clean_images.device)
            batch_size = clean_images.shape[0]

            # Sample a set of random time steps for each image in mini-batch
            timesteps = torch.randint(
                0, noise_scheduler.num_train_timesteps, (batch_size,), device=clean_images.device)
            
            noisy_images=noise_scheduler.add_noise(clean_images, noise, timesteps)
            
            with accelerator.accumulate(model):
                noise_pred = model(noisy_images,timesteps)["sample"]
                loss = torch.nn.functional.mse_loss(noise_pred,noise)
                accelerator.backward(loss)
                
                accelerator.clip_grad_norm_(model.parameters(),1.0)
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()
                
            progress_bar.update(1)
            logs = {
                "loss" : loss.detach().item(),
                "lr" : lr_scheduler.get_last_lr()[0],
            }
            progress_bar.set_postfix(**logs)
    
    accelerator.unwrap_model(model)

    args = (config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)

    accelerate.notebook_launcher(train_loop, args, num_processes=1)

@torch.no_grad()
def sample(unet, scheduler,seed,save_process_dir=None):
        torch.manual_seed(seed)
        
        if save_process_dir:
            if not os.path.exists(save_process_dir):
                os.mkdir(save_process_dir)
        
        scheduler.set_timesteps(1000)
        image=torch.randn((1,1,32,32)).to(model.device)
        num_steps=max(noise_scheduler.timesteps).numpy()
        
        for t in noise_scheduler.timesteps:
            model_output=unet(image,t)['sample']
            image=scheduler.step(model_output,int(t),image,generator=None)['prev_sample']
            if save_process_dir:
                save_image=torchvision.transforms.ToPILImage()(image.squeeze(0))
                save_image.resize((256,256)).save(
                    os.path.join(save_process_dir,"seed-"+str(seed)+"_"+f"{num_steps-t.numpy():03d}"+".png"),format="png")
        
        return torchvision.transforms.ToPILImage()(image.squeeze(0))
  

test_image=sample(model,noise_scheduler,2)
test_image.resize((265,256))

test_image=sample(model,noise_scheduler,5)
test_image.resize((256,256))

test_image=sample(model,noise_scheduler,1991)
test_image.resize((256,256))

#not recognizabel

test_image=sample(model,noise_scheduler,2022)
test_image.resize((256,256))

test_image=sample(model,noise_scheduler,42)
test_image.resize((256,256))


#read the image
#(X_train,y_train),(X_test,y_test)=keras.datasets.mnist.load_data()
#x_train = X_train.astype("float32") / 255.0

#test_image = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(256, 256))
#test_image = tf.keras.preprocessing.image.load_img(x_train[0], target_size=(256, 256))
#test_image = tf.keras.preprocessing.image.load_img(sample_image, target_size=(256, 256))
#test_image = tf.keras.preprocessing.image.img_to_array(x_train[0])

#predict_denoised_image(autoencoder, test_image)
